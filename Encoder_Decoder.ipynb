{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8450 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rawValue</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>month_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rawValue  day_of_week  hour_of_day  month_of_year  day_of_month  state\n",
       "0      -0.4            5            1              1             1      1\n",
       "1      -1.1            5            2              1             1      1\n",
       "2      -0.3            5            3              1             1      1\n",
       "3      -0.6            5            4              1             1      1\n",
       "4      -0.4            5            5              1             1      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"data/15038_O3_2022_processed.csv\"\n",
    "data = pd.read_csv(folder)\n",
    "\n",
    "value_to_use = 'rawValue'\n",
    "target = 'state'\n",
    "\n",
    "columns_to_keep = [value_to_use, 'day_of_week', 'hour_of_day', 'month_of_year', 'day_of_month', target]\n",
    "data = data[columns_to_keep]\n",
    "nb_pos_class = (data[target] == 1).sum()\n",
    "nb_neg_class = (data[target] == 0).sum()\n",
    "print(nb_pos_class, nb_neg_class)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rawValue_scaled</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>month_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010365</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007863</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010722</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009650</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010365</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rawValue_scaled  day_of_week  hour_of_day  month_of_year  day_of_month  \\\n",
       "0         0.010365            5            1              1             1   \n",
       "1         0.007863            5            2              1             1   \n",
       "2         0.010722            5            3              1             1   \n",
       "3         0.009650            5            4              1             1   \n",
       "4         0.010365            5            5              1             1   \n",
       "\n",
       "   state  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data[value_to_use+'_scaled'] = scaler.fit_transform(data[value_to_use].values.reshape(-1, 1))\n",
    "columns_to_keep = [value_to_use+'_scaled', 'day_of_week', 'hour_of_day', 'month_of_year', 'day_of_month', target]\n",
    "data = data[columns_to_keep]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Creating sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(input_data, labels, sequence_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(input_data) - sequence_length):\n",
    "        X.append(input_data[i:i+sequence_length])  # Sequence of length 48\n",
    "        y.append(labels[i+sequence_length])       # Label for the next timestep (n+49)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Defining train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_ratio):\n",
    "    train_size = int(len(data) * split_ratio)\n",
    "    # Split the data\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:]\n",
    "\n",
    "    # Count the number of '-1' states in each set\n",
    "    count_train_neg1 = (train_data[target] == 0).sum()\n",
    "    count_test_neg1 = (test_data[target] == 0).sum()\n",
    "\n",
    "    print(count_train_neg1, \"negative example in train\")\n",
    "    print(count_test_neg1, \"negative example in test\")\n",
    "\n",
    "    if count_train_neg1 == 0 or count_test_neg1 == 0:\n",
    "        print(\"No negative class in one of the set\")\n",
    "        return None, None\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_set(train_data, sequence_length):\n",
    "    labels = train_data[target].values\n",
    "    input_data = train_data.drop([target], axis=1).values\n",
    "    X, y = sliding_window(input_data, labels, sequence_length)\n",
    "    X_train = torch.tensor(X, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y, dtype=torch.long)  # Convert labels to torch.long\n",
    "    return X_train, y_train\n",
    "\n",
    "def get_test_set(test_data, sequence_length):\n",
    "    labels = test_data[target].values\n",
    "    input_data = test_data.drop([target], axis=1).values\n",
    "    X, y = sliding_window(input_data, labels, sequence_length)\n",
    "    X_test = torch.tensor(X, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y, dtype=torch.long)  # Convert labels to torch.long\n",
    "    return X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 negative example in train\n",
      "8 negative example in test\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "split_ratio = 0.6\n",
    "sequence_length = 48\n",
    "num_epochs = 10\n",
    "\n",
    "train_data, test_data = split_data(data, split_ratio)\n",
    "X_train, y_train = get_train_set(train_data, sequence_length)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size)\n",
    "\n",
    "X_test, y_test = get_test_set(test_data, sequence_length)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2, dropout=0.5):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        output, (hidden, cell) = self.lstm(input_seq)\n",
    "        return hidden, cell\n",
    "\n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers=2, dropout=0.5):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, hidden, cell):\n",
    "        # We didnt have time to fully construct it, so we just use a FC layer\n",
    "        output = self.fc_out(hidden[-1])  # Using the last hidden state\n",
    "        return output\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source):\n",
    "        hidden, cell = self.encoder(source)\n",
    "        output = self.decoder(hidden, cell)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1555\n",
      "Epoch 2/10, Loss: 0.0459\n",
      "Epoch 3/10, Loss: 0.0459\n",
      "Epoch 4/10, Loss: 0.0457\n",
      "Epoch 5/10, Loss: 0.0457\n",
      "Epoch 6/10, Loss: 0.0458\n",
      "Epoch 7/10, Loss: 0.0456\n",
      "Epoch 8/10, Loss: 0.0456\n",
      "Epoch 9/10, Loss: 0.0456\n",
      "Epoch 10/10, Loss: 0.0456\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "encoder = EncoderLSTM(input_size=5, hidden_size=32, num_layers=2, dropout=0.5)\n",
    "decoder = DecoderLSTM(hidden_size=32, output_size=2, num_layers=2, dropout=0.5)\n",
    "seq2seq = Seq2Seq(encoder, decoder, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Loss function and optimizer\n",
    "\n",
    "# Calculate class weights\n",
    "# class_weights = torch.tensor([nb_pos_class/(nb_pos_class+nb_neg_class), nb_neg_class/(nb_pos_class+nb_neg_class)], dtype=torch.float32).to(seq2seq.device)\n",
    "\n",
    "# Initialize the loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Assuming y_batch is of shape [batch_size, sequence_length] and we need the last label\n",
    "        X_batch, y_batch = X_batch.to(seq2seq.device), y_batch.to(seq2seq.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = seq2seq(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in y_test: {0: 8, 1: 3342}\n"
     ]
    }
   ],
   "source": [
    "# Convert y_test to a NumPy array for easy manipulation\n",
    "y_test_np = y_test.numpy()\n",
    "\n",
    "# Count the number of instances of each class\n",
    "unique, counts = np.unique(y_test_np, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Class Distribution in y_test:\", class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model in evaluation mode\n",
    "seq2seq.eval()\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(seq2seq.device), y_batch.to(seq2seq.device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = seq2seq(X_batch)\n",
    "        predicted_labels = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative : 0 False negative : 0 \n",
      "True positive : 3342 False Positive : 8 \n",
      "\n",
      "Positive Class Precision: 0.9976\n",
      "Positive Class Recall: 1.0000\n",
      "Positive Class F1 Score: 0.9988\n",
      "--------------------------\n",
      "Negative Class Precision: nan\n",
      "Negative Class Recall: 0.0000\n",
      "Negative Class F1 Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/c_sm71w14ln3qcp7vmb68ctc0000gn/T/ipykernel_912/2644543267.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision_neg = tn / (tn + fn)\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to arrays for evaluation metrics\n",
    "all_predictions = np.array(all_predictions).flatten()\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "#print(conf_matrix.ravel())\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "print(\"True negative :\", tn, \"False negative :\", fn, \"\\nTrue positive :\", tp, \"False Positive :\", fp, \"\\n\")\n",
    "\n",
    "# Calculate metrics for the positive class (1)\n",
    "precision_pos = tp / (tp + fp)\n",
    "recall_pos = tp / (tp + fn)\n",
    "f1_pos = 2 * (precision_pos * recall_pos) / (precision_pos + recall_pos)\n",
    "\n",
    "# Calculate metrics for the negative class (0)\n",
    "precision_neg = tn / (tn + fn)\n",
    "recall_neg = tn / (tn + fp)\n",
    "f1_neg = 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Positive Class Precision: {precision_pos:.4f}')\n",
    "print(f'Positive Class Recall: {recall_pos:.4f}')\n",
    "print(f'Positive Class F1 Score: {f1_pos:.4f}')\n",
    "print(\"--------------------------\")\n",
    "print(f'Negative Class Precision: {precision_neg:.4f}')\n",
    "print(f'Negative Class Recall: {recall_neg:.4f}')\n",
    "print(f'Negative Class F1 Score: {f1_neg:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
